{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c04147",
   "metadata": {},
   "source": [
    "## Script for automated Download of Sentinel-3 LST Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02961f",
   "metadata": {},
   "source": [
    "### Create Environment and select Kernel\n",
    "\n",
    "Before you run the script, you need to create the environment defined in the file sentinel_env.yml. Therefore, use Anaconda Promt following these steps:\n",
    "- Open Anaconda Promt\n",
    "- Write: \"conda env create -n sentinel_env -f 'insert path to environment file ending with sentinel_env.yml'\"\n",
    "- Press Enter\n",
    "- In the next line, write: \"activate sentinel_env\"\n",
    "- Press Enter\n",
    "- If the next line starts with (sentinel_env), you have been successful\n",
    "- To create the kernel, write: „python -m ipykernel install --user --name sentinel_env --display-name sentinel_env_kernel“\n",
    "- If you are having troubles, you can find help here: https://docs.conda.io/projects/conda/en/4.6.0/user-guide/troubleshooting.html\n",
    "- ...and useful commands here: https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf\n",
    "- In Jupiter Notebook, click kernel in the menu bar, select change kernel, choose sentinel_env_kernel\n",
    "- If it says sentinle_env_kernel in the upper right corner, you are ready to run the script!\n",
    "\n",
    "Please note, that the environment works for Windows only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1640bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt, Polygon\n",
    "from sentinelsat import read_geojson\n",
    "from datetime import date, datetime, timedelta\n",
    "from requests.exceptions import ChunkedEncodingError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb862e27",
   "metadata": {},
   "source": [
    "### Defining important Variables\n",
    "\n",
    "The user needs to specify the following variables:\n",
    "- username: The username for the Copernicus Open Dataspace login.\n",
    "- password: The password for the Copernicus Open Dataspace login.\n",
    "- kenya_aoi: The corner coordinates of the bounding box (Polygon - Extend Area) of the aoi.\n",
    "- collection_product: The name of the Sentinel collection product (for LST: \"SL_2_LST\", for SYN: \"SY_2_SYN\").\n",
    "- start_date: The start date of the desired aquisition period.\n",
    "- end_date: The end date of the desired aquisition period.\n",
    "- start_time: The start time for the LST Daytime aquisitions.\n",
    "- end_time: The end time for the LST Daytime aquisitions.\n",
    "- output_dir: The path to the directory to store the downloaded Sentinel zip-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e784e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copernicus Data Space credentials\n",
    "#username = \"example@email.de\"\n",
    "#password = \"Password\"\n",
    "\n",
    "username = \"kiwi@rssgmbh.de\"\n",
    "password = \"1WNHO8D8GeSNNtoflQZX!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2686cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds Polygon: POLYGON ((33.909587860107365 -4.720417022704964, 33.909587860107365 4.633819103241024, 41.88752365112305 4.633819103241024, 41.88752365112305 -4.720417022704964, 33.909587860107365 -4.720417022704964))\n",
      "WKT of Bounds Polygon: POLYGON ((33.9095878601073650 -4.7204170227049644, 33.9095878601073650 4.6338191032410236, 41.8875236511230469 4.6338191032410236, 41.8875236511230469 -4.7204170227049644, 33.9095878601073650 -4.7204170227049644))\n"
     ]
    }
   ],
   "source": [
    "# kenya_aoi = \"POLYGON ((33.9095878601073650 -4.7204170227049644, 41.8875236511230540 -4.7204170227049644, 41.8875236511230540 4.6338191032410290, 33.9095878601073650 4.6338191032410290, 33.9095878601073650 -4.7204170227049644))\"\n",
    "\n",
    "# Prompt the user for input to confirm the download\n",
    "aoi_filename_input = str(input(\"Please enter the name of the AOI vector file located in 'AOI_Files' folder:\"))\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"./AOI_Files/\"\n",
    "\n",
    "# Find the matching file in the folder\n",
    "matching_files = [f for f in os.listdir(folder_path) if aoi_filename_input in f]\n",
    "\n",
    "if matching_files:\n",
    "    # Use the first matched file as the AOI filepath\n",
    "    aoi_filepath = os.path.join(folder_path, matching_files[0])\n",
    "    \n",
    "    # Load it as a GeoDataFrame\n",
    "    aoi_gdf = gpd.read_file(aoi_filepath)\n",
    "    \n",
    "    # Check if the GeoDataFrame is not empty and has a geometry column\n",
    "    if not aoi_gdf.empty and 'geometry' in aoi_gdf.columns:\n",
    "        # Calculate the total bounds of all geometries in the GeoDataFrame\n",
    "        minx, miny, maxx, maxy = aoi_gdf.total_bounds\n",
    "        \n",
    "        # Create a Polygon from the total bounds\n",
    "        bounds_polygon = Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny), (minx, miny)])\n",
    "        \n",
    "        print(\"Bounds Polygon:\", bounds_polygon)  # Print the Polygon object\n",
    "        \n",
    "        # Convert the bounds Polygon to WKT format\n",
    "        kenya_aoi = wkt.dumps(bounds_polygon)\n",
    "        print(\"WKT of Bounds Polygon:\", kenya_aoi)  # Print the WKT string\n",
    "    else:\n",
    "        print(\"The GeoDataFrame is empty or missing a geometry column.\")\n",
    "else:\n",
    "    print(\"No matching files found in the 'AOI_Files' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63365ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Type: SL_2_LST\n",
      "Start Date: 2020-06-01\n",
      "End Date: 2020-07-01\n",
      "Time Range: 06:00:00 to 15:00:00\n",
      "Max Records: 1000\n",
      "Output Directory: ./Download/S3_LST\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to select a product type\n",
    "product_input = input(\"Please enter the product type (LST or SYN): \").strip().upper()\n",
    "\n",
    "if product_input == \"LST\":\n",
    "    collection_product = \"SL_2_LST\"\n",
    "    output_dir = r'./Download/S3_LST'\n",
    "elif product_input == \"SYN\":\n",
    "    collection_product = \"SY_2_SYN\"\n",
    "    output_dir = r'./Download/S3_SYN'\n",
    "else:\n",
    "    print(\"Invalid product type. Please enter either 'LST' or 'SYN'.\")\n",
    "    exit(1)\n",
    "\n",
    "# Prompt the user for the start and end dates\n",
    "start_date_input = input(\"Please enter the start date (YYYY MM DD): \").strip()\n",
    "end_date_input = input(\"Please enter the end date (YYYY MM DD): \").strip()\n",
    "\n",
    "try:\n",
    "    # Parse the start date\n",
    "    start_date_parts = [int(part) for part in start_date_input.split()]\n",
    "    start_date = date(start_date_parts[0], start_date_parts[1], start_date_parts[2])\n",
    "    \n",
    "    # Parse the end date\n",
    "    end_date_parts = [int(part) for part in end_date_input.split()]\n",
    "    end_date = date(end_date_parts[0], end_date_parts[1], end_date_parts[2])\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid date format: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Define the time range\n",
    "start_time = \"06:00:00\"\n",
    "end_time = \"15:00:00\"\n",
    "\n",
    "# Define max records / search\n",
    "maxRecords = 1000 # number of records to search (maximum = 1000)\n",
    "\n",
    "# Print the results to verify\n",
    "print(f\"Product Type: {collection_product}\")\n",
    "print(f\"Start Date: {start_date}\")\n",
    "print(f\"End Date: {end_date}\")\n",
    "print(f\"Time Range: {start_time} to {end_time}\")\n",
    "print(f\"Max Records: {maxRecords}\")\n",
    "print(f\"Output Directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6da54",
   "metadata": {},
   "source": [
    "### Creating Copernicus Open Dataspace Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75709c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access token\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"grant_type\": \"password\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "            data = data,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Access token creation failed. Response from server was: {r.json()}\"\n",
    "        )\n",
    "    return r.json()[\"access_token\"]\n",
    "\n",
    "access_token = get_access_token(username, password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb931f",
   "metadata": {},
   "source": [
    "### Searching the Catalogue with OData\n",
    "\n",
    "Please note: If the number of products is 1000, the maximum number has been reached. The actual number might be larger, but it stops counting at 1000. Go back to the defining variables section and decrease the search period by adapting start and end date. Run another query, until the number is below 1000. You can download the missing data in a new run afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b85198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the query\n",
    "json = requests.get(\n",
    "    \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,\"\n",
    "    f\"'{collection_product}')%20and%20OData.CSC.Intersects(area=geography'SRID=4326;\"\n",
    "    f\"{kenya_aoi}')%20and%20ContentDate/Start%20gt%20\"\n",
    "    f\"{start_date}T00:00:00.000Z%20and%20ContentDate/End%20lt%20\"\n",
    "    f\"{end_date}T00:00:00.000Z&$top={maxRecords}\"\n",
    ").json()\n",
    "len(json['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f41e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@odata.mediaContentType</th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>ContentLength</th>\n",
       "      <th>OriginDate</th>\n",
       "      <th>PublicationDate</th>\n",
       "      <th>ModificationDate</th>\n",
       "      <th>Online</th>\n",
       "      <th>EvictionDate</th>\n",
       "      <th>S3Path</th>\n",
       "      <th>Checksum</th>\n",
       "      <th>ContentDate</th>\n",
       "      <th>Footprint</th>\n",
       "      <th>GeoFootprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>a88cd7b7-2358-59f5-9905-cd59e370f328</td>\n",
       "      <td>S3A_SL_2_LST____20200601T185613_20200601T18581...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-02T23:59:09.294Z</td>\n",
       "      <td>2020-06-03T00:05:11.135Z</td>\n",
       "      <td>2020-06-03T00:05:11.135Z</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>/eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Start': '2020-06-01T18:56:12.610Z', 'End': '...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((54.2666 1.93894,...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[54.2666,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>ce761011-8307-5f23-9e8a-49cf805bb361</td>\n",
       "      <td>S3B_SL_2_LST____20200601T195741_20200601T19594...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-03T01:27:18.209Z</td>\n",
       "      <td>2020-06-03T01:31:36.381Z</td>\n",
       "      <td>2020-06-03T01:31:36.381Z</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>/eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Start': '2020-06-01T19:57:41.081Z', 'End': '...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((38.8378 1.94599,...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[38.8378,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>927b707a-ac22-5d25-805a-34710b040251</td>\n",
       "      <td>S3B_SL_2_LST____20200601T195940_20200601T20024...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-03T02:46:23.765Z</td>\n",
       "      <td>2020-06-03T02:53:29.631Z</td>\n",
       "      <td>2020-06-03T02:53:29.631Z</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>/eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Start': '2020-06-01T19:59:40.352Z', 'End': '...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((36.6641 12.4824,...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[36.6641,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>908b4bed-96ad-5918-ae8b-eea7bc9dbee6</td>\n",
       "      <td>S3B_SL_2_LST____20200602T065636_20200602T06593...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-03T12:59:33.383Z</td>\n",
       "      <td>2020-06-03T13:04:21.939Z</td>\n",
       "      <td>2020-06-03T13:04:21.939Z</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>/eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/02/S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Start': '2020-06-02T06:56:35.688Z', 'End': '...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((34.2621 -10.5552...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[34.2621,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>38460b9c-913c-5d89-9ee9-30b58915eb9a</td>\n",
       "      <td>S3B_SL_2_LST____20200602T065336_20200602T06563...</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-03T13:02:33.450Z</td>\n",
       "      <td>2020-06-03T13:02:26.269Z</td>\n",
       "      <td>2020-06-03T13:02:26.269Z</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>/eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/02/S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'Start': '2020-06-02T06:53:35.688Z', 'End': '...</td>\n",
       "      <td>geography'SRID=4326;POLYGON ((36.7954 -0.06773...</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[36.7954,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    @odata.mediaContentType                                    Id  \\\n",
       "0  application/octet-stream  a88cd7b7-2358-59f5-9905-cd59e370f328   \n",
       "1  application/octet-stream  ce761011-8307-5f23-9e8a-49cf805bb361   \n",
       "2  application/octet-stream  927b707a-ac22-5d25-805a-34710b040251   \n",
       "3  application/octet-stream  908b4bed-96ad-5918-ae8b-eea7bc9dbee6   \n",
       "4  application/octet-stream  38460b9c-913c-5d89-9ee9-30b58915eb9a   \n",
       "\n",
       "                                                Name  \\\n",
       "0  S3A_SL_2_LST____20200601T185613_20200601T18581...   \n",
       "1  S3B_SL_2_LST____20200601T195741_20200601T19594...   \n",
       "2  S3B_SL_2_LST____20200601T195940_20200601T20024...   \n",
       "3  S3B_SL_2_LST____20200602T065636_20200602T06593...   \n",
       "4  S3B_SL_2_LST____20200602T065336_20200602T06563...   \n",
       "\n",
       "                ContentType  ContentLength                OriginDate  \\\n",
       "0  application/octet-stream              0  2020-06-02T23:59:09.294Z   \n",
       "1  application/octet-stream              0  2020-06-03T01:27:18.209Z   \n",
       "2  application/octet-stream              0  2020-06-03T02:46:23.765Z   \n",
       "3  application/octet-stream              0  2020-06-03T12:59:33.383Z   \n",
       "4  application/octet-stream              0  2020-06-03T13:02:33.450Z   \n",
       "\n",
       "            PublicationDate          ModificationDate  Online EvictionDate  \\\n",
       "0  2020-06-03T00:05:11.135Z  2020-06-03T00:05:11.135Z    True                \n",
       "1  2020-06-03T01:31:36.381Z  2020-06-03T01:31:36.381Z    True                \n",
       "2  2020-06-03T02:53:29.631Z  2020-06-03T02:53:29.631Z    True                \n",
       "3  2020-06-03T13:04:21.939Z  2020-06-03T13:04:21.939Z    True                \n",
       "4  2020-06-03T13:02:26.269Z  2020-06-03T13:02:26.269Z    True                \n",
       "\n",
       "                                              S3Path Checksum  \\\n",
       "0  /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...       []   \n",
       "1  /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...       []   \n",
       "2  /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/01/S...       []   \n",
       "3  /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/02/S...       []   \n",
       "4  /eodata/Sentinel-3/SLSTR/SL_2_LST/2020/06/02/S...       []   \n",
       "\n",
       "                                         ContentDate  \\\n",
       "0  {'Start': '2020-06-01T18:56:12.610Z', 'End': '...   \n",
       "1  {'Start': '2020-06-01T19:57:41.081Z', 'End': '...   \n",
       "2  {'Start': '2020-06-01T19:59:40.352Z', 'End': '...   \n",
       "3  {'Start': '2020-06-02T06:56:35.688Z', 'End': '...   \n",
       "4  {'Start': '2020-06-02T06:53:35.688Z', 'End': '...   \n",
       "\n",
       "                                           Footprint  \\\n",
       "0  geography'SRID=4326;POLYGON ((54.2666 1.93894,...   \n",
       "1  geography'SRID=4326;POLYGON ((38.8378 1.94599,...   \n",
       "2  geography'SRID=4326;POLYGON ((36.6641 12.4824,...   \n",
       "3  geography'SRID=4326;POLYGON ((34.2621 -10.5552...   \n",
       "4  geography'SRID=4326;POLYGON ((36.7954 -0.06773...   \n",
       "\n",
       "                                        GeoFootprint  \n",
       "0  {'type': 'Polygon', 'coordinates': [[[54.2666,...  \n",
       "1  {'type': 'Polygon', 'coordinates': [[[38.8378,...  \n",
       "2  {'type': 'Polygon', 'coordinates': [[[36.6641,...  \n",
       "3  {'type': 'Polygon', 'coordinates': [[[34.2621,...  \n",
       "4  {'type': 'Polygon', 'coordinates': [[[36.7954,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dictionary to dataframe\n",
    "products_df = pd.DataFrame.from_dict(json['value'])\n",
    "\n",
    "# Print the first five products to see if the query worked\n",
    "products_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6140b",
   "metadata": {},
   "source": [
    "### Filter Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28716f",
   "metadata": {},
   "source": [
    "#### Filter Records by Daytime\n",
    "\n",
    "The Sentinel-3 SLSTR Level-2 LST product provides a measure of how hot or cold the 'surface' of the Earth would feel to the touch. Usually, it is recorded during daytime and nighttime. We are only interested in the daytime acquisitions, which is why we need to specify a time range to filter the acquisitions. In case of Kenya, that time range is set to 6 am to 3 pm, since Kenya is roughly two hours ahead of UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc0cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the strings for the start and end time to time objects\n",
    "start_time = datetime.strptime(start_time, \"%H:%M:%S\").time()\n",
    "end_time = datetime.strptime(end_time, \"%H:%M:%S\").time()\n",
    "\n",
    "products_daytime = {}\n",
    "products_list = json.get('value', {})\n",
    "\n",
    "for product in products_list:\n",
    "    contentDate = product['ContentDate']\n",
    "    product_id = product['Id']\n",
    "    \n",
    "    # Extract the start and end time of the products and convert them to time objects\n",
    "    start_datetime = datetime.strptime(contentDate.get('Start'), \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    end_datetime = datetime.strptime(contentDate.get('End'), \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    start_datetime = datetime.strptime(start_datetime.strftime('%H:%M:%S'), '%H:%M:%S').time()    \n",
    "    end_datetime = datetime.strptime(end_datetime.strftime('%H:%M:%S'), '%H:%M:%S').time()\n",
    "    \n",
    "    # Filter out products with acquisition times outside the set range\n",
    "    if start_time <= start_datetime <= end_time or start_time <= end_datetime <= end_time:\n",
    "        products_daytime[product_id] = product\n",
    "  \n",
    "len(products_daytime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ced91",
   "metadata": {},
   "source": [
    "#### Filter for Non-Timecritical Frames\n",
    "\n",
    "The instrument data from Sentinel-3 SLSTR can be disseminated in 'stripes', 'frames', or 'tiles'. Since we are only interested in frames, we need to filter the data for products of a certain naming pattern accoring to the naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3c48ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for a specific structure of the instance id (part of the name)\n",
    "from re import Match\n",
    "\n",
    "products_nonTimeCritical = {}\n",
    "\n",
    "pattern = r\"\\d{4}_\\d{3}_\\d{3}_\\d{4}\"\n",
    "product_id = pd.DataFrame.from_dict(products_daytime).loc['Id',].to_list()  # type: ignore\n",
    "# print(product_id)\n",
    "\n",
    "for product in product_id:\n",
    "    product_id = product\n",
    "    product = products_daytime[product]\n",
    "    name = product['Name']\n",
    "    \n",
    "    match = re.search(pattern, name)\n",
    "    \n",
    "    if match:\n",
    "        products_nonTimeCritical[product_id] = product\n",
    "        \n",
    "len(products_nonTimeCritical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6be5961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Products:  213\n",
      "Number of Daytime Products:  105\n",
      "Number of Non-Timecritical Products:  105\n"
     ]
    }
   ],
   "source": [
    "# Print the number of total products, filtered products by daytime, and non-time-critical frames\n",
    "print(\"Total Number of Products: \", len(products_df))\n",
    "print(\"Number of Daytime Products: \", len(products_daytime))\n",
    "print(\"Number of Non-Timecritical Products: \", len(products_nonTimeCritical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fc917",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786e7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Non-Timecritical Frames to download: 105\n"
     ]
    }
   ],
   "source": [
    "# Get the list of existing files in the output directory\n",
    "existing_files = os.listdir(output_dir)\n",
    "print(existing_files)\n",
    "\n",
    "# Iterate over the non-timecritical frames\n",
    "download_frames = {}\n",
    "product_id = pd.DataFrame.from_dict(products_nonTimeCritical).loc['Id',].to_list()\n",
    "\n",
    "for product in product_id:\n",
    "    product_id = product\n",
    "    product_file = products_nonTimeCritical[product]\n",
    "    # Extract the titel of the product\n",
    "    title = products_nonTimeCritical[product]['Name']\n",
    "    \n",
    "    # Append the .zip extension to the title\n",
    "    zip_title = title + \".zip\"\n",
    "    \n",
    "    # Append the .SEN3 extension to the title\n",
    "    sen_title = title + \".SEN3\"\n",
    "    \n",
    "    # Check if the zip or sen file with the same title already exists\n",
    "    if zip_title not in existing_files and sen_title not in existing_files:\n",
    "        download_frames[product_id] = product_file\n",
    "\n",
    "# Print the number of non-time-critical frames that need to be downloaded\n",
    "print('Non-Timecritical Frames to download:', len(download_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e635a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Attempt 1/5) Downloading 'S3B_SL_2_LST____20200602T065636_20200602T065936_20200603T123253_0179_039_291_3060_LN2_O_NT_004.zip' ...\n",
      "Successfully downloaded 'S3B_SL_2_LST____20200602T065636_20200602T065936_20200603T123253_0179_039_291_3060_LN2_O_NT_004.zip' to './Download/S3_LST'.\n",
      "\n",
      "(Attempt 1/5) Downloading 'S3B_SL_2_LST____20200602T065336_20200602T065636_20200603T123245_0179_039_291_2880_LN2_O_NT_004.zip' ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, file_name), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m):\n\u001b[1;32m     40\u001b[0m             file\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully downloaded \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/eoenv/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from unittest import skip\n",
    "\n",
    "# Promt the user for input to confirm the download\n",
    "user_input = input(\"Do you want to download the data? (yes/ no):\")\n",
    "\n",
    "if user_input.lower() == \"yes\":\n",
    "\n",
    "    # Extract Id of selected products for download\n",
    "    product_id = pd.DataFrame.from_dict(download_frames).loc['Id',].to_list()\n",
    "    access_token = get_access_token(username, password)\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    session = requests.Session()\n",
    "\n",
    "    for product in product_id:\n",
    "        title = download_frames[product]['Name']\n",
    "        file_name = title.replace('SEN3', 'zip')\n",
    "        url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product})/$value\"\n",
    "\n",
    "        response = session.get(url, headers=headers, stream=True)\n",
    "\n",
    "        # Check if the access tokem is still valid\n",
    "        while response.status_code == 401:\n",
    "\n",
    "            # Token expired, generate new one\n",
    "            access_token = get_access_token(username, password)\n",
    "            headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "            session.headers.update(headers)\n",
    "            response = session.get(url, headers=headers, stream=True)\n",
    "\n",
    "        max_attempts = 5\n",
    "        attempts = 0\n",
    "\n",
    "        while attempts < max_attempts:\n",
    "            try:\n",
    "                print(f\"\\n(Attempt {attempts + 1}/{max_attempts}) Downloading '{file_name}' ...\")\n",
    "                # Your download code here\n",
    "                if response.status_code == 200:\n",
    "                    with open(os.path.join(output_dir, file_name), \"wb\") as file:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            file.write(chunk)\n",
    "                    print(f\"Successfully downloaded '{file_name}' to '{output_dir}'.\")\n",
    "                    break  # Break out of the loop if download succeeds\n",
    "                else:\n",
    "                    print(f\"Error: Received status code {response.status_code} when attempting to download '{file_name}'.\")\n",
    "            except ChunkedEncodingError as e:\n",
    "                print(f\"Warning: Download interrupted due '{e}'. Retrying...\")\n",
    "                attempts += 1\n",
    "\n",
    "        if attempts == max_attempts:\n",
    "            print(f\"Failed to download '{file_name}' after {max_attempts} attempts.\")\n",
    "            continue\n",
    "\n",
    "        # # If the request was successful, proceed with downloading\n",
    "        # if response.status_code == 200:\n",
    "        #     with open(os.path.join(output_dir, file_name), \"wb\") as file:\n",
    "        #         for chunk in response.iter_content(chunk_size=5192):\n",
    "        #             if chunk:\n",
    "        #                 file.write(chunk)\n",
    "        # else:\n",
    "        #     print(f\"Error downloading product {product}, status code: {response.status_code}\")\n",
    "\n",
    "elif user_input.lower() == \"no\":\n",
    "    print(\"Download cancelled.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Invalid input. Download cancelled.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
